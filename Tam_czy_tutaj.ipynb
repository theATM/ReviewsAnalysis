{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Oto moja kopia zadania numer siedem"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import scraper\n",
    "import translator\n",
    "import sentimentAnalysis\n",
    "import graphAnalysis\n",
    "import utils\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "importlib.reload(scraper)\n",
    "from nltk.corpus import wordnet\n",
    "from itertools import chain\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Wczytywanie danych - Data Load\n",
    "oneonetwo = pd.read_csv(\"data\"+os.sep+\"part\"+os.sep+\"Suomi112_cpd.csv\", encoding='utf-8-sig')\n",
    "sos_live = pd.read_csv(\"data\"+os.sep+\"part\"+os.sep+\"SosLive_cpd.csv\", encoding='utf-8-sig')\n",
    "#Połączenie danych - Data Concat\n",
    "data = pd.concat([oneonetwo,sos_live],ignore_index = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Lista Indykatorów - List of indicators\n",
    "lista_indykatorow = [\"perceived_ease_of_use\", \"perceived_usefulness\", \"satisfaction\", \"attitude\", \"behavioral_intentions\"]\n",
    "#Stworzyłem poszczególne listy słów kluczy: - I created lists of the keyword:\n",
    "slowa_klucze  = \\\n",
    "{\n",
    "    \"perceived_ease_of_use\" : [\"simple\",\"easy\",\"intuitive\",\"convenience\",\"explainable\",\"quick\",\"speed\",\"children\",\"elderly\"],\n",
    "    \"perceived_usefulness\"  : [\"efficient\", \"useful\", \"helpful\", \"work\", \"effective\",\"revolutionary\",\"implement\"],\n",
    "    \"satisfaction\"          : [\"satisfaction\",\"satisfy\", \"fulfill\", \"gratify\", \"meet\", \"beneficial\", \"content\", \"happy\", \"appeasement\"],\n",
    "    \"attitude\"              : [ \"important\", \"emotion\", \"attitude\", \"opinion\", \"grade\"],\n",
    "    \"behavioral_intentions\" : [\"usage\",\"intentions\", \"interaction\",\"plan\",\"utilize\",\"behavioral\"],\n",
    "}\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Ta funkcja tworzy listę synonimóœ i nie tylku z listy słów - This function creates a list of synonyms and more from the list of words\n",
    "def dobierz_synonimy_i_nie_tylko(slowa):\n",
    "    slowa_klucze_zwrotne = []\n",
    "    for slowo in slowa:\n",
    "        slowa_klucze_zwrotne.append(slowo)\n",
    "        #Synonims:\n",
    "        synonimy = []\n",
    "        for syn in wordnet.synsets(slowo):\n",
    "            for s in syn.lemmas():\n",
    "                synonimy.append(s.name())\n",
    "        slowa_klucze_zwrotne.extend(synonimy)\n",
    "\n",
    "        #Hypernims:\n",
    "        parabole = []\n",
    "        for par in wordnet.synsets(slowo):\n",
    "            for p in par.hypernyms():\n",
    "                for pl in p.lemmas():\n",
    "                    parabole.append(pl.name())\n",
    "        slowa_klucze_zwrotne.extend(parabole)\n",
    "\n",
    "        zmiekczenia = []\n",
    "        for zmi in wordnet.synsets(slowo):\n",
    "            for zm in zmi.hyponyms():\n",
    "                for z in zm.lemmas():\n",
    "                    zmiekczenia.append(z.name())\n",
    "        slowa_klucze_zwrotne.extend(zmiekczenia)\n",
    "\n",
    "    return(set(slowa_klucze_zwrotne))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Wyszukiwanie synonimów:\n",
    "slowa_klucze[\"perceived_ease_of_use\"] = dobierz_synonimy_i_nie_tylko(slowa_klucze[\"perceived_ease_of_use\"])\n",
    "slowa_klucze[\"perceived_usefulness\"] = dobierz_synonimy_i_nie_tylko(slowa_klucze[\"perceived_usefulness\"] )\n",
    "slowa_klucze[\"satisfaction\"] = dobierz_synonimy_i_nie_tylko(slowa_klucze[\"satisfaction\"] )\n",
    "slowa_klucze[\"attitude\"] = dobierz_synonimy_i_nie_tylko(slowa_klucze[\"attitude\"])\n",
    "slowa_klucze[\"behavioral_intentions\"] = dobierz_synonimy_i_nie_tylko(slowa_klucze[\"behavioral_intentions\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Można wypisać wyniczki - sanity check data presentation:\n",
    "slowa_klucze[\"attitude\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preprocessing danych:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import utils, importlib\n",
    "importlib.reload(utils) # to keep the .py file up to date when coding\n",
    "processor = utils.Processor() # Init preprocessing <- there is a path to set up where to dowloads this v\n",
    "processor.ini_dowload() #dowload all the nessesary files to do the preprocesing (like the dictionary of the stopwords)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "def preprocesing_danych(dane_dane_danedu_dane_danedu_uu):\n",
    "    dane = dane_dane_danedu_dane_danedu_uu\n",
    "    dane = processor.preprocess(str(dane))\n",
    "    dane = processor.tokenize(dane)\n",
    "    dane = processor.remove_stopwords(dane,remove_len=3) # Remove stopwords (like in the topic task)\n",
    "    dane = processor.process_tokens(dane)  # Strip the words into the root words\n",
    "    #dane = pos_tag(dane)\n",
    "    return dane"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "slowa_klucze[\"perceived_ease_of_use\"]  = preprocesing_danych(slowa_klucze[\"perceived_ease_of_use\"])\n",
    "slowa_klucze[\"perceived_usefulness\"]   = preprocesing_danych(slowa_klucze[\"perceived_usefulness\"] )\n",
    "slowa_klucze[\"satisfaction\"]           = preprocesing_danych(slowa_klucze[\"satisfaction\"]         )\n",
    "slowa_klucze[\"attitude\"]               = preprocesing_danych(slowa_klucze[\"attitude\"]             )\n",
    "slowa_klucze[\"behavioral_intentions\"]  = preprocesing_danych(slowa_klucze[\"behavioral_intentions\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wszystkie_slowa_klucze = []\n",
    "wszystkie_slowa_klucze.append(slowa_klucze[\"perceived_ease_of_use\"])\n",
    "wszystkie_slowa_klucze.append(slowa_klucze[\"perceived_usefulness\"] )\n",
    "wszystkie_slowa_klucze.append(slowa_klucze[\"satisfaction\"] )\n",
    "wszystkie_slowa_klucze.append(slowa_klucze[\"attitude\"] )\n",
    "wszystkie_slowa_klucze.append(slowa_klucze[\"behavioral_intentions\"] )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "keyword_dictionary = Dictionary(wszystkie_slowa_klucze)\n",
    "keyword_bow_corpus = [keyword_dictionary.doc2bow(doc) for doc in wszystkie_slowa_klucze] #  dictionary reporting how many words and how many times those words appear\n",
    "from gensim import corpora, models\n",
    "keyword_tfidf = models.TfidfModel(keyword_bow_corpus)\n",
    "corpus_tfidf = keyword_tfidf[keyword_bow_corpus]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Preproces the reviews:\n",
    "data[\"preprocessed_reviews\"] = data[\"content\"].apply(lambda x: preprocesing_danych(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Vectorize the reviews:\n",
    "from gensim.corpora import Dictionary\n",
    "review_dictionary = Dictionary(data[\"preprocessed_reviews\"])\n",
    "review_bow_corpus = [review_dictionary.doc2bow(doc) for doc in data[\"preprocessed_reviews\"]] #  dictionary reporting how many words and how many times those words appear\n",
    "data_vectorized = keyword_tfidf[review_bow_corpus]\n",
    "data[\"vectorized_reviews\"] = data_vectorized.corpus"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Classification:\n",
    "from thefuzz import fuzz\n",
    "from thefuzz import process\n",
    "import numpy as np\n",
    "def classify(rewiew,all_keywords,threshold=10):\n",
    "    rewiew = \" \".join(rewiew)\n",
    "    scores = []\n",
    "    for keywords in all_keywords:\n",
    "        keywords = \" \".join(keywords)\n",
    "        scores.append(fuzz.token_set_ratio(rewiew,keywords))\n",
    "    if max(scores) < threshold: #scores are from 0 to 100\n",
    "        return -1\n",
    "    best = np.argmax(scores) #ID of the best keyword\n",
    "    return best\n",
    "\n",
    "data[\"class\"] = data[\"preprocessed_reviews\"].apply(lambda x : classify(x, wszystkie_slowa_klucze))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data[\"class\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create five horses of the TAM indicators\n",
    "horse_ease_of_use     =    data.drop(data[data[\"class\"] != 0].index)\n",
    "horse_usefulness      =    data.drop(data[data[\"class\"] != 1].index)\n",
    "horse_satisfaction    =    data.drop(data[data[\"class\"] != 2].index)\n",
    "horse_attitude        =    data.drop(data[data[\"class\"] != 3].index)\n",
    "horse_behavioral      =    data.drop(data[data[\"class\"] != 4].index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}