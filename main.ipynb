{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from google_play_scraper import app\n",
    "from app_store_scraper import AppStore\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import scrapper\n",
    "oneonetwo = scrapper.google_scrapp(app_id = 'fi.digia.suomi112',country='fi')\n",
    "emergencyplus = scrapper.google_scrapp(app_id = 'com.threesixtyentertainment.nesn',country='fi')\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11.9kB [00:00, 13.4MB/s]                   \n"
     ]
    }
   ],
   "source": [
    "from easynmt import EasyNMT\n",
    "import os\n",
    "import torch\n",
    "device = torch.device(\"cuda\")\n",
    "model = EasyNMT('opus-mt',cache_folder= \"cache/transformers\",device = device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception: Helsinki-NLP/opus-mt-br-en is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
      "If this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Helsinki-NLP/opus-mt-br-en is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mHTTPError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[0;32m~/Documents/Studies/Semestr9/NLP/ReviewsAnalysis/renv/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:213\u001B[0m, in \u001B[0;36mhf_raise_for_status\u001B[0;34m(response, endpoint_name)\u001B[0m\n\u001B[1;32m    212\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 213\u001B[0m     \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_for_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m HTTPError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/Documents/Studies/Semestr9/NLP/ReviewsAnalysis/renv/lib/python3.10/site-packages/requests/models.py:941\u001B[0m, in \u001B[0;36mResponse.raise_for_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    940\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m http_error_msg:\n\u001B[0;32m--> 941\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m HTTPError(http_error_msg, response\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m)\n",
      "\u001B[0;31mHTTPError\u001B[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/Helsinki-NLP/opus-mt-br-en/resolve/main/source.spm",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mRepositoryNotFoundError\u001B[0m                   Traceback (most recent call last)",
      "File \u001B[0;32m~/Documents/Studies/Semestr9/NLP/ReviewsAnalysis/renv/lib/python3.10/site-packages/transformers/utils/hub.py:409\u001B[0m, in \u001B[0;36mcached_file\u001B[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001B[0m\n\u001B[1;32m    407\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    408\u001B[0m     \u001B[38;5;66;03m# Load from URL or cache if already cached\u001B[39;00m\n\u001B[0;32m--> 409\u001B[0m     resolved_file \u001B[38;5;241m=\u001B[39m \u001B[43mhf_hub_download\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    410\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    411\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    412\u001B[0m \u001B[43m        \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    413\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    414\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    415\u001B[0m \u001B[43m        \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    416\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    417\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    418\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    419\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_auth_token\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_auth_token\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    420\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    421\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    423\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m RepositoryNotFoundError:\n",
      "File \u001B[0;32m~/Documents/Studies/Semestr9/NLP/ReviewsAnalysis/renv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1053\u001B[0m, in \u001B[0;36mhf_hub_download\u001B[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, use_auth_token, local_files_only, legacy_cache_layout)\u001B[0m\n\u001B[1;32m   1052\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1053\u001B[0m     metadata \u001B[38;5;241m=\u001B[39m \u001B[43mget_hf_file_metadata\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1054\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1055\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_auth_token\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_auth_token\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1056\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1057\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43metag_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1058\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1059\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m EntryNotFoundError \u001B[38;5;28;01mas\u001B[39;00m http_error:\n\u001B[1;32m   1060\u001B[0m     \u001B[38;5;66;03m# Cache the non-existence of the file and raise\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Studies/Semestr9/NLP/ReviewsAnalysis/renv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1359\u001B[0m, in \u001B[0;36mget_hf_file_metadata\u001B[0;34m(url, use_auth_token, proxies, timeout)\u001B[0m\n\u001B[1;32m   1350\u001B[0m r \u001B[38;5;241m=\u001B[39m _request_wrapper(\n\u001B[1;32m   1351\u001B[0m     method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHEAD\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1352\u001B[0m     url\u001B[38;5;241m=\u001B[39murl,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1357\u001B[0m     timeout\u001B[38;5;241m=\u001B[39mtimeout,\n\u001B[1;32m   1358\u001B[0m )\n\u001B[0;32m-> 1359\u001B[0m \u001B[43mhf_raise_for_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43mr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1361\u001B[0m \u001B[38;5;66;03m# Return\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Studies/Semestr9/NLP/ReviewsAnalysis/renv/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:242\u001B[0m, in \u001B[0;36mhf_raise_for_status\u001B[0;34m(response, endpoint_name)\u001B[0m\n\u001B[1;32m    234\u001B[0m     message \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    235\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;241m.\u001B[39mstatus_code\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m Client Error.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    236\u001B[0m         \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    240\u001B[0m         \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mIf the repo is private, make sure you are authenticated.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    241\u001B[0m     )\n\u001B[0;32m--> 242\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m RepositoryNotFoundError(message, response) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    244\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m400\u001B[39m:\n",
      "\u001B[0;31mRepositoryNotFoundError\u001B[0m: 401 Client Error. (Request ID: JPjr8LjgRaUYUVbLgAliU)\n\nRepository Not Found for url: https://huggingface.co/Helsinki-NLP/opus-mt-br-en/resolve/main/source.spm.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf the repo is private, make sure you are authenticated.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [18], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m oneonetwo[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtranslatedContent\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43moneonetwo\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcontent\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtranslate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_lang\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43men\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Studies/Semestr9/NLP/ReviewsAnalysis/renv/lib/python3.10/site-packages/pandas/core/series.py:4774\u001B[0m, in \u001B[0;36mSeries.apply\u001B[0;34m(self, func, convert_dtype, args, **kwargs)\u001B[0m\n\u001B[1;32m   4664\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[1;32m   4665\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   4666\u001B[0m     func: AggFuncType,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4669\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   4670\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[1;32m   4671\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   4672\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[1;32m   4673\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4772\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[1;32m   4773\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 4774\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Studies/Semestr9/NLP/ReviewsAnalysis/renv/lib/python3.10/site-packages/pandas/core/apply.py:1100\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1097\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_str()\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# self.f is Callable\u001B[39;00m\n\u001B[0;32m-> 1100\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Studies/Semestr9/NLP/ReviewsAnalysis/renv/lib/python3.10/site-packages/pandas/core/apply.py:1151\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1149\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1150\u001B[0m         values \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m)\u001B[38;5;241m.\u001B[39m_values\n\u001B[0;32m-> 1151\u001B[0m         mapped \u001B[38;5;241m=\u001B[39m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1152\u001B[0m \u001B[43m            \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1153\u001B[0m \u001B[43m            \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1154\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1155\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1157\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[1;32m   1158\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[1;32m   1159\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[1;32m   1160\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[0;32m~/Documents/Studies/Semestr9/NLP/ReviewsAnalysis/renv/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2919\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[0;34m()\u001B[0m\n",
      "Cell \u001B[0;32mIn [18], line 1\u001B[0m, in \u001B[0;36m<lambda>\u001B[0;34m(x)\u001B[0m\n\u001B[0;32m----> 1\u001B[0m oneonetwo[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtranslatedContent\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m oneonetwo[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtranslate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_lang\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43men\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/Documents/Studies/Semestr9/NLP/ReviewsAnalysis/renv/lib/python3.10/site-packages/easynmt/EasyNMT.py:154\u001B[0m, in \u001B[0;36mEasyNMT.translate\u001B[0;34m(self, documents, target_lang, source_lang, show_progress_bar, beam_size, batch_size, perform_sentence_splitting, paragraph_split, sentence_splitter, document_language_detection, **kwargs)\u001B[0m\n\u001B[1;32m    152\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    153\u001B[0m         logger\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mException: \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;28mstr\u001B[39m(e))\n\u001B[0;32m--> 154\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    156\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_single_doc \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(output) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    157\u001B[0m     output \u001B[38;5;241m=\u001B[39m output[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/Documents/Studies/Semestr9/NLP/ReviewsAnalysis/renv/lib/python3.10/site-packages/easynmt/EasyNMT.py:149\u001B[0m, in \u001B[0;36mEasyNMT.translate\u001B[0;34m(self, documents, target_lang, source_lang, show_progress_bar, beam_size, batch_size, perform_sentence_splitting, paragraph_split, sentence_splitter, document_language_detection, **kwargs)\u001B[0m\n\u001B[1;32m    147\u001B[0m method_args[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdocuments\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m [documents[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m ids]\n\u001B[1;32m    148\u001B[0m method_args[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msource_lang\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m lng\n\u001B[0;32m--> 149\u001B[0m translated \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtranslate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmethod_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    150\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx, translated_sentences \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(ids, translated):\n\u001B[1;32m    151\u001B[0m     output[idx] \u001B[38;5;241m=\u001B[39m translated_sentences\n",
      "File \u001B[0;32m~/Documents/Studies/Semestr9/NLP/ReviewsAnalysis/renv/lib/python3.10/site-packages/easynmt/EasyNMT.py:181\u001B[0m, in \u001B[0;36mEasyNMT.translate\u001B[0;34m(self, documents, target_lang, source_lang, show_progress_bar, beam_size, batch_size, perform_sentence_splitting, paragraph_split, sentence_splitter, document_language_detection, **kwargs)\u001B[0m\n\u001B[1;32m    177\u001B[0m     sent2doc\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mlen\u001B[39m(splitted_sentences))\n\u001B[1;32m    178\u001B[0m \u001B[38;5;66;03m#logger.info(\"Sentence splitting done after: {:.2f} sec\".format(time.time() - start_time))\u001B[39;00m\n\u001B[1;32m    179\u001B[0m \u001B[38;5;66;03m#logger.info(\"Translate {} sentences\".format(len(splitted_sentences)))\u001B[39;00m\n\u001B[0;32m--> 181\u001B[0m translated_sentences \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtranslate_sentences\u001B[49m\u001B[43m(\u001B[49m\u001B[43msplitted_sentences\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_lang\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget_lang\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msource_lang\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msource_lang\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbeam_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeam_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    183\u001B[0m \u001B[38;5;66;03m# Merge sentences back to documents\u001B[39;00m\n\u001B[1;32m    184\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n",
      "File \u001B[0;32m~/Documents/Studies/Semestr9/NLP/ReviewsAnalysis/renv/lib/python3.10/site-packages/easynmt/EasyNMT.py:278\u001B[0m, in \u001B[0;36mEasyNMT.translate_sentences\u001B[0;34m(self, sentences, target_lang, source_lang, show_progress_bar, beam_size, batch_size, **kwargs)\u001B[0m\n\u001B[1;32m    275\u001B[0m     iterator \u001B[38;5;241m=\u001B[39m tqdm\u001B[38;5;241m.\u001B[39mtqdm(iterator, total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(sentences)\u001B[38;5;241m/\u001B[39mscale, unit_scale\u001B[38;5;241m=\u001B[39mscale, smoothing\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m    277\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m start_idx \u001B[38;5;129;01min\u001B[39;00m iterator:\n\u001B[0;32m--> 278\u001B[0m     output\u001B[38;5;241m.\u001B[39mextend(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtranslator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtranslate_sentences\u001B[49m\u001B[43m(\u001B[49m\u001B[43msentences_sorted\u001B[49m\u001B[43m[\u001B[49m\u001B[43mstart_idx\u001B[49m\u001B[43m:\u001B[49m\u001B[43mstart_idx\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msource_lang\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msource_lang\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_lang\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget_lang\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbeam_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeam_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    280\u001B[0m \u001B[38;5;66;03m#Restore original sorting of sentences\u001B[39;00m\n\u001B[1;32m    281\u001B[0m output \u001B[38;5;241m=\u001B[39m [output[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m np\u001B[38;5;241m.\u001B[39margsort(length_sorted_idx)]\n",
      "File \u001B[0;32m~/Documents/Studies/Semestr9/NLP/ReviewsAnalysis/renv/lib/python3.10/site-packages/easynmt/models/OpusMT.py:40\u001B[0m, in \u001B[0;36mOpusMT.translate_sentences\u001B[0;34m(self, sentences, source_lang, target_lang, device, beam_size, **kwargs)\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtranslate_sentences\u001B[39m(\u001B[38;5;28mself\u001B[39m, sentences: List[\u001B[38;5;28mstr\u001B[39m], source_lang: \u001B[38;5;28mstr\u001B[39m, target_lang: \u001B[38;5;28mstr\u001B[39m, device: \u001B[38;5;28mstr\u001B[39m, beam_size: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     39\u001B[0m     model_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHelsinki-NLP/opus-mt-\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m-\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(source_lang, target_lang)\n\u001B[0;32m---> 40\u001B[0m     tokenizer, model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     41\u001B[0m     model\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     43\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m tokenizer(sentences, truncation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_length, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/Studies/Semestr9/NLP/ReviewsAnalysis/renv/lib/python3.10/site-packages/easynmt/models/OpusMT.py:22\u001B[0m, in \u001B[0;36mOpusMT.load_model\u001B[0;34m(self, model_name)\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     21\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoad model: \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m+\u001B[39mmodel_name)\n\u001B[0;32m---> 22\u001B[0m     tokenizer \u001B[38;5;241m=\u001B[39m \u001B[43mMarianTokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m     model \u001B[38;5;241m=\u001B[39m MarianMTModel\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_name)\n\u001B[1;32m     24\u001B[0m     model\u001B[38;5;241m.\u001B[39meval()\n",
      "File \u001B[0;32m~/Documents/Studies/Semestr9/NLP/ReviewsAnalysis/renv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1734\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001B[0m\n\u001B[1;32m   1732\u001B[0m         resolved_vocab_files[file_id] \u001B[38;5;241m=\u001B[39m download_url(file_path, proxies\u001B[38;5;241m=\u001B[39mproxies)\n\u001B[1;32m   1733\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1734\u001B[0m         resolved_vocab_files[file_id] \u001B[38;5;241m=\u001B[39m \u001B[43mcached_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1735\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1736\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfile_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1737\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1738\u001B[0m \u001B[43m            \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1739\u001B[0m \u001B[43m            \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1740\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1741\u001B[0m \u001B[43m            \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1742\u001B[0m \u001B[43m            \u001B[49m\u001B[43muse_auth_token\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_auth_token\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1743\u001B[0m \u001B[43m            \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1744\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1745\u001B[0m \u001B[43m            \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1746\u001B[0m \u001B[43m            \u001B[49m\u001B[43m_raise_exceptions_for_missing_entries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1747\u001B[0m \u001B[43m            \u001B[49m\u001B[43m_raise_exceptions_for_connection_errors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1748\u001B[0m \u001B[43m            \u001B[49m\u001B[43m_commit_hash\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcommit_hash\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1749\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1750\u001B[0m         commit_hash \u001B[38;5;241m=\u001B[39m extract_commit_hash(resolved_vocab_files[file_id], commit_hash)\n\u001B[1;32m   1752\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(unresolved_files) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/Documents/Studies/Semestr9/NLP/ReviewsAnalysis/renv/lib/python3.10/site-packages/transformers/utils/hub.py:424\u001B[0m, in \u001B[0;36mcached_file\u001B[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001B[0m\n\u001B[1;32m    409\u001B[0m     resolved_file \u001B[38;5;241m=\u001B[39m hf_hub_download(\n\u001B[1;32m    410\u001B[0m         path_or_repo_id,\n\u001B[1;32m    411\u001B[0m         filename,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    420\u001B[0m         local_files_only\u001B[38;5;241m=\u001B[39mlocal_files_only,\n\u001B[1;32m    421\u001B[0m     )\n\u001B[1;32m    423\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m RepositoryNotFoundError:\n\u001B[0;32m--> 424\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[1;32m    425\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is not a local folder and is not a valid model identifier \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    426\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlisted on \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://huggingface.co/models\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mIf this is a private repository, make sure to \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    427\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpass a token having permission to this repo with `use_auth_token` or log in with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    428\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`huggingface-cli login` and pass `use_auth_token=True`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    429\u001B[0m     )\n\u001B[1;32m    430\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m RevisionNotFoundError:\n\u001B[1;32m    431\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[1;32m    432\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrevision\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    433\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfor this model name. Check the model page at \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    434\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://huggingface.co/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m for available revisions.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    435\u001B[0m     )\n",
      "\u001B[0;31mOSError\u001B[0m: Helsinki-NLP/opus-mt-br-en is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`."
     ]
    }
   ],
   "source": [
    "oneonetwo['translatedContent'] = oneonetwo['content'].apply(lambda x: model.translate(x, target_lang=\"en\",max_length=2))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "oneonetwo.to_csv(r\"Suomi.csv\", encoding='utf-8-sig')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "#com.emc.emergency\n",
    "#com.threesixtyentertainment.nesn\n",
    "'''result = app(\n",
    "    'fi.digia.suomi112',\n",
    "    lang='en', # defaults to 'en'\n",
    "    country='us' # defaults to 'us'\n",
    ")\n",
    "print(result)\n",
    "'''\n",
    "from easynmt import EasyNMT\n",
    "model = EasyNMT(\"opus-mt\")\n",
    "\n",
    "from google_play_scraper import Sort, reviews_all\n",
    "\n",
    "googlePlay_suomi112_reviews = reviews_all(\n",
    "    'fi.digia.suomi112',\n",
    "    sleep_milliseconds=0, # defaults to 0\n",
    "    lang='en', # defaults to 'en'\n",
    "    country='fi', # defaults to 'us'\n",
    "    sort=Sort.NEWEST, # defaults to Sort.MOST_RELEVANT\n",
    ")\n",
    "googlePlay_suomi112_dataframe = pd.DataFrame(np.array(googlePlay_suomi112_reviews), columns=['review'])\n",
    "\n",
    "\n",
    "googlePlay_suomi112_dataframe = googlePlay_suomi112_dataframe.join(pd.DataFrame(googlePlay_suomi112_dataframe.pop('review').tolist()))\n",
    "\n",
    "googlePlay_suomi112_dataframe.drop(['userImage', 'repliedAt', 'replyContent'], axis=1, inplace=True)\n",
    "\n",
    "googlePlay_suomi112_dataframe['translatedContent'] = googlePlay_suomi112_dataframe['content'].apply(lambda x: model.translate(x, target_lang=\"en\").text)\n",
    "\n",
    "googlePlay_suomi112_dataframe.to_csv(r\"C:\\Users\\yanns\\OneDrive\\Bureau\\googlePlaySuomi.csv\", encoding='utf-8-sig')\n",
    "\n",
    "#print(googlePlay_suomi112_reviews)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "appStore_suomi112 = AppStore(country='fi', app_name='112 Suomi', app_id = '998281396')\n",
    "appStore_suomi112.review(how_many=100)\n",
    "\n",
    "appStore_suomi112_dataframe = pd.DataFrame(np.array(appStore_suomi112.reviews),columns=['review'])\n",
    "\n",
    "review_dataframe.to_csv(\"Suomi.csv\",encoding='utf-8-sig')\n",
    "\n",
    "appStore_suomi112_dataframe.to_csv(r\"C:\\Users\\yanns\\OneDrive\\Bureau\\appStoreSuomi.csv\", encoding='utf-8-sig')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "#Translate a single sentence to German\n",
    "print(model.translate('This is a sentence we want to translate to German', target_lang='de'))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['You can define the list in sentences.', 'All sentences will be translated into your target language.', 'Note that you can also mix phrases with languages.']\n"
     ]
    }
   ],
   "source": [
    "#Translate several sentences to German\n",
    "sentences = ['Voit määritellä listan lauseilla.', 'Kaikki lauseet käännetään kohdekielellesi.', 'Huomaa, että voit myös sekoittaa lauseiden kieliä.']\n",
    "print(model.translate(sentences, target_lang='en',max_length=512))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Translate several sentences to German\n",
    "sentences = ['Voit määritellä listan lauseilla.', 'Kaikki lauseet käännetään kohdekielellesi.', 'Huomaa, että voit myös sekoittaa lauseiden kieliä.']\n",
    "print(model.translate(sentences, target_lang='en'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}