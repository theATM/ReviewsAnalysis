{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Tasks 5 - Topic Generation\n",
    "This notebook will us LDA topic modeling to create the 10 topics.\n",
    "Both the Bag of words and TIIDF vectorisation techniques will be used with the LDA.\n",
    "### This notebook pipeline\n",
    "- data loading and concatenation\n",
    "- data preprocessing\n",
    "- dictionary and corpus creation\n",
    "- ifidf data vectorisation\n",
    "- lda topic modeling (with bag of words and tfidf)\n",
    "- topic testing on the reviews and the new data\n",
    "\n",
    "The topic LDA modeling code was mostly taken from this article:\n",
    "https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the data:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Get the data from files\n",
    "import os\n",
    "import importlib\n",
    "import pandas as pd\n",
    "oneonetwo_data = pd.read_csv(\"data\"+os.sep+\"part\"+os.sep+\"Suomi112_eng.csv\", encoding='utf-8-sig')['content']\n",
    "sos_live = pd.read_csv(\"data\"+os.sep+\"part\"+os.sep+\"SosLive_eng.csv\", encoding='utf-8-sig')['content']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Concatanate data from two apps\n",
    "data = pd.concat([oneonetwo_data,sos_live],ignore_index = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocess the data:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize the processor object:\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "processor = utils.Processor()\n",
    "processor.ini_dowload()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Preprocess the data:\n",
    "data = data.apply(lambda x: processor.preprocess(str(x)))\n",
    "data = data.apply(lambda x: processor.tokenize(x))\n",
    "data = data.apply(lambda x: processor.remove_stopwords(x))\n",
    "data = data.apply(lambda x: processor.process_tokens(x))\n",
    "data\n",
    "data_copy = data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create dictionary and corpus:\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Create dictionary - containing the number of times a word appears in the dataset\n",
    "flat_data = [tag for sentence in data for tag in sentence ]\n",
    "from gensim.corpora import Dictionary\n",
    "dictionary = Dictionary(data)\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000) #Remove unused and over used tokens\n",
    "# dictionary reporting how many words and how many times those words appear:\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in data]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bow_corpus[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Dictionary can be printed out:\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#One can check how many times one word apears in the dict:\n",
    "bow_rewiew = bow_corpus[2]\n",
    "for i in range(len(bow_rewiew)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_rewiew[i][0],dictionary[bow_rewiew[i][0]],bow_rewiew[i][1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Vectorize using the tfidf:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Create tf idf vector representation of the words in the data:\n",
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#preview TF-IDF scores for our first document.\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LDA topic modeling:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Topics with simple bag of words\n",
    "import gensim\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Topics with TFiDF vectorisation:\n",
    "import gensim\n",
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Topic testing:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test on one review (with tfidf representation)\n",
    "print(\"Review: \", data[1])\n",
    "rewiew = bow_corpus[1]\n",
    "for index, score in sorted(lda_model_tfidf[rewiew], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#test on the new data\n",
    "unseen_document = \"This application drains battery!\"\n",
    "tmp =  processor.preprocess(str(unseen_document))\n",
    "tmp = processor.tokenize(tmp)\n",
    "tmp = processor.remove_stopwords(tmp)\n",
    "preprocessed_document = processor.process_tokens(tmp)\n",
    "bow_vector = dictionary.doc2bow(preprocessed_document)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test on bag on words topics:\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test on tfidf topics:\n",
    "for index, score in sorted(lda_model_tfidf[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}