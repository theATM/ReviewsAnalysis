{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Tasks 6 - Random Forest Classification\n",
    "This notebook will train machine learning model using ngram representation of the reviews. To check the most important features in the reviews\n",
    "### This notebook pipeline\n",
    "- data loading\n",
    "- remove neutral reviews\n",
    "- data preprocessing\n",
    "- train/test dataset splitting\n",
    "- data vectorisation\n",
    "- create random forest classifier\n",
    "- train model\n",
    "- evaluate model\n",
    "- feature extraction\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the data:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import utils, importlib\n",
    "importlib.reload(utils)\n",
    "oneonetwo_data = pd.read_csv(\"data\"+os.sep+\"part\"+os.sep+\"Suomi112_cpd.csv\", encoding='utf-8-sig')\n",
    "sos_live = pd.read_csv(\"data\"+os.sep+\"part\"+os.sep+\"SosLive_cpd.csv\", encoding='utf-8-sig')\n",
    "data = pd.concat([oneonetwo_data,sos_live],ignore_index = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Print the loaded data:\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Print data stats:\n",
    "import utils, importlib\n",
    "importlib.reload(utils)\n",
    "utils.count_data_stat(data,use_labels=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Recode the sentiment:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Recode the sentiment\n",
    "import utils, importlib\n",
    "importlib.reload(utils)\n",
    "# Remove Neutral Reviews:\n",
    "data = data.drop(data[data[\"sentiment\"] == utils.sentiment_dict[\"Neutral\"]].index)\n",
    "# Recode the Negative sentiment from -1 to 0\n",
    "data['sentiment'] = [utils.labels_dict[\"Positive\"] if sent == utils.sentiment_dict[\"Positive\"] else utils.labels_dict[\"Negative\"] for sent in data['sentiment']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocess the data:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Preprocess the data\n",
    "import utils, importlib\n",
    "importlib.reload(utils) # to keep the .py file up to date when coding\n",
    "processor = utils.Processor() # Init preprocessing <- there is a path to set up where to dowloads this v\n",
    "processor.ini_dowload() #dowload all the nessesary files to do the preprocesing (like the dictionary of the stopwords)\n",
    "data['content'] = data['content'].apply(lambda x: processor.preprocess(str(x))) #Used to get rid of the unnesesary characters and to stringify the emogis\n",
    "data['content'] = data['content'].apply(lambda x: processor.tokenize(x)) # This is needed in the mext steps\n",
    "data['content'] = data['content'].apply(lambda x: processor.not_no(x)) # This is needed in the mext steps\n",
    "data['content'] = data['content'].apply(lambda x: processor.remove_stopwords(x,remove_len=3)) # Remove stopwords (like in the topic task)\n",
    "data['content'] = data['content'].apply(lambda x: processor.process_tokens(x))  # Strip the words into the root words\n",
    "data['content'] = data['content'].apply(lambda x: processor.detokenize(x)) # Go back form tokens to text. Because sklearn Vektorizer neads text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create the test/train subsets:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Check the distribution of the data\n",
    "import utils, importlib\n",
    "importlib.reload(utils)\n",
    "utils.count_data_stat(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#make data more balanced by removing additional data - optional (or use weigths in the classifier)\n",
    "#rem_idxs = data[data.sentiment==sentiment_dict[\"Positive\"]].sample(frac = 0.5,random_state=0).index\n",
    "#data = data.drop(rem_idxs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#split the data to train i test sets\n",
    "test = data.sample(frac = 0.2,random_state=1)\n",
    "train = data.drop(test.index)\n",
    "#print(\"Siema Janek\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Print the test/train proportions:\n",
    "print(\"Train: \",len(train.content))\n",
    "utils.count_data_stat(train)\n",
    "print(\"Test: \", len(test.content))\n",
    "utils.count_data_stat(test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Vectorise the reviews data:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Vectorize the text into features model can understand:\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "vectorizer = TfidfVectorizer(ngram_range = (2,3))\n",
    "vectorizer.fit(list(train['content']))\n",
    "train_X = vectorizer.transform(list(train['content']))\n",
    "test_X = vectorizer.transform(list(test['content']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Machine Learning model:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Choose and create classifier aka model aka clf:\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Feel free to change the params of the model to make them better:\n",
    "clf = RandomForestClassifier(n_estimators=350, max_depth=25,min_samples_leaf=2,min_samples_split=2,max_features=\"sqrt\", criterion=\"gini\", random_state=0,oob_score=False, class_weight={0:1,1:0.5})\n",
    "#clf = svm.SVC(kernel = \"poly\",degree=3, gamma=\"scale\", C=1000,class_weight={0:1,1:0.5})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training the machine learing model:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#And train it:\n",
    "clf.fit(train_X, train['sentiment'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model evaluation:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Perform the predicitons - go with grand of salt - this in unbalanced dataset\n",
    "#And print out the accuracies - mind the class unbalance!\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_Y = clf.predict(train_X)\n",
    "train_acc = accuracy_score(train['sentiment'],train_Y)\n",
    "print(\"Training Acc = \",train_acc)\n",
    "\n",
    "test_Y = clf.predict(test_X)\n",
    "test_acc = accuracy_score(test['sentiment'],test_Y)\n",
    "print(\"Test Acc = \",test_acc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compute the confusion matrix function for training data and testing data respectively - best visualize of the model performance\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "labels = ['happy', 'sad']\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Calculate the confusion matrix when classifying the training data\n",
    "ax[0].title.set_text('Training data confusion matrix:')\n",
    "cm = confusion_matrix(train['sentiment'],train_Y)\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=['Negative', 'Positive'])\n",
    "cmd.plot(ax=ax[0])\n",
    "\n",
    "# Calculate the confusion matrix when classifying the testing data\n",
    "ax[1].title.set_text('Testing data confusion matrix:')\n",
    "cm2 = confusion_matrix(test['sentiment'],test_Y)\n",
    "cmd2 = ConfusionMatrixDisplay(cm2, display_labels=['Negative', 'Positive'])\n",
    "cmd2.plot(ax=ax[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature extraction:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Create Feature selection tool:\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "sel = SelectFromModel(clf,prefit=True, max_features = 200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Select N best features and print them:\n",
    "from itertools import compress\n",
    "features = pd.DataFrame()\n",
    "features[\"idx\"] = sel.get_support(indices=True)\n",
    "features[\"importance\"] = sel.estimator.feature_importances_[features[\"idx\"]]\n",
    "features[\"names\"] =  np.array(vectorizer.get_feature_names_out())[features[\"idx\"]]\n",
    "features[\"prediction\"] = clf.predict(vectorizer.transform(features[\"names\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Print extracted features at the end:\n",
    "features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}