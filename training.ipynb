{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Load transated data with sentiment calculated\n",
    "import utils, importlib\n",
    "importlib.reload(utils)\n",
    "data1g = pd.read_csv(\"data\"+os.sep+\"part\"+os.sep+\"Suomi112_cpd_google.csv\", encoding='utf-8-sig')\n",
    "data1g.drop(['Unnamed: 0','userName', 'reviewId', 'at','reviewCreatedVersion','score','thumbsUpCount'], axis=1, inplace=True)\n",
    "data1g['type'] = utils.souce_type_dict[\"Suomi112_google\"]\n",
    "data1a = pd.read_csv(\"data\"+os.sep+\"part\"+os.sep+\"Suomi112_cpd_apple.csv\", encoding='utf-8-sig')\n",
    "data1a.drop(['Unnamed: 0','title', 'date', 'rating'], axis=1, inplace=True)\n",
    "data1a['type'] = utils.souce_type_dict[\"Suomi112_apple\"]\n",
    "data2g = pd.read_csv(\"data\"+os.sep+\"part\"+os.sep+\"SosLive_cpd_google.csv\", encoding='utf-8-sig')\n",
    "data2g.drop(['Unnamed: 0','userName', 'reviewId', 'at','reviewCreatedVersion','score','thumbsUpCount'], axis=1, inplace=True)\n",
    "data2g['type'] = utils.souce_type_dict[\"SosLive_google\"]\n",
    "data2a = pd.read_csv(\"data\"+os.sep+\"part\"+os.sep+\"SosLive_cpd_apple.csv\", encoding='utf-8-sig')\n",
    "data2a.drop(['Unnamed: 0','title', 'date', 'rating','developerResponse'], axis=1, inplace=True)\n",
    "data2a['type'] = utils.souce_type_dict[\"SosLive_apple\"]\n",
    "#Merge all sources into one big dataframe (the type attrib will remember the source)\n",
    "data = pd.concat([data1g,data1a,data2g,data2a],ignore_index = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "oneonetwo_data = pd.read_csv(\"data\"+os.sep+\"part\"+os.sep+\"Suomi112_cpd.csv\", encoding='utf-8-sig')\n",
    "sos_live = pd.read_csv(\"data\"+os.sep+\"part\"+os.sep+\"SosLive_cpd.csv\", encoding='utf-8-sig')\n",
    "data = pd.concat([oneonetwo_data,sos_live],ignore_index = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Print the loaded data:\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Recode the sentiment\n",
    "import utils, importlib\n",
    "importlib.reload(utils)\n",
    "# Remove Neutral Reviews:\n",
    "data = data.drop(data[data[\"sentiment\"] == 0].index)\n",
    "# Recode the Negative sentiment from -1 to 0\n",
    "data['sentiment'] = [sent if sent == 1 else 0 for sent in data['sentiment']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Preprocess the data\n",
    "import utils, importlib\n",
    "importlib.reload(utils) # to keep the .py file up to date when coding\n",
    "processor = utils.Processor() # Init preprocessing <- there is a path to set up where to dowloads this v\n",
    "processor.ini_dowload() #dowload all the nessesary files to do the preprocesing (like the dictionary of the stopwords)\n",
    "data['content'] = data['content'].apply(lambda x: processor.preprocess(str(x))) #Used to get rid of the unnesesary characters and to stringify the emogis\n",
    "data['content'] = data['content'].apply(lambda x: processor.tokenize(x)) # This is needed in the mext steps\n",
    "data['content'] = data['content'].apply(lambda x: processor.remove_stopwords(x,remove_len=2)) # Remove stopwords (like in the topic task)\n",
    "data['content'] = data['content'].apply(lambda x: processor.process_tokens(x))  # Strip the words into the root words\n",
    "data['content'] = data['content'].apply(lambda x: processor.detokenize(x)) # Go back form tokens to text. Because sklearn Vektorizer neads text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Check the distribution of the data\n",
    "import utils, importlib\n",
    "importlib.reload(utils)\n",
    "utils.count_data_stat(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#make data more balanced - optional (or use weigths in the classifier)\n",
    "#rem_idxs = data[data.sentiment==sentiment_dict[\"Positive\"]].sample(frac = 0.5,random_state=0).index\n",
    "#data = data.drop(rem_idxs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#split the data to train i test sets\n",
    "test = data.sample(frac = 0.2,random_state=0)\n",
    "train = data.drop(test.index)\n",
    "#print(\"Siema Janek\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Print the test/train proportions:\n",
    "print(\"Train: \",len(train.content))\n",
    "utils.count_data_stat(train)\n",
    "print(\"Test: \", len(test.content))\n",
    "utils.count_data_stat(test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Vectorize the text into features model can understand:\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "vectorizer = TfidfVectorizer(ngram_range = (2,3))\n",
    "vectorizer.fit(list(train['content']))\n",
    "train_X = vectorizer.transform(list(train['content']))\n",
    "test_X = vectorizer.transform(list(test['content']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Choose and create classifier aka model aka clf:\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Feel free to change the params of the model to make them better:\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=200,min_samples_leaf=1,max_features=\"sqrt\", criterion=\"gini\", random_state=0, class_weight={0:1,1:0.5})\n",
    "#clf = svm.SVC(kernel = \"poly\",degree=3, gamma=\"scale\", C=1000,class_weight={0:1,1:0.5})\n",
    "#And train it:\n",
    "clf.fit(train_X, train['sentiment'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Perform the predicitons\n",
    "#And print out the accuracies - mind the class unbalance!\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_Y = clf.predict(train_X)\n",
    "train_acc = accuracy_score(train['sentiment'],train_Y)\n",
    "print(\"Training Acc = \",train_acc)\n",
    "\n",
    "test_Y = clf.predict(test_X)\n",
    "test_acc = accuracy_score(test['sentiment'],test_Y)\n",
    "print(\"Test Acc = \",test_acc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compute the confusion matrix function for training data and testing data respectively - best visualize of the model performance\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "labels = ['happy', 'sad']\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Calculate the confusion matrix when classifying the training data\n",
    "ax[0].title.set_text('Training data confusion matrix:')\n",
    "cm = confusion_matrix(train['sentiment'],train_Y)\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=['Negative', 'Positive'])\n",
    "cmd.plot(ax=ax[0])\n",
    "\n",
    "# Calculate the confusion matrix when classifying the testing data\n",
    "ax[1].title.set_text('Testing data confusion matrix:')\n",
    "cm2 = confusion_matrix(test['sentiment'],test_Y)\n",
    "cmd2 = ConfusionMatrixDisplay(cm2, display_labels=['Negative', 'Positive'])\n",
    "cmd2.plot(ax=ax[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "########Feature extraction:\n",
    "#Create Feature selection tool:\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "sel = SelectFromModel(clf,prefit=True, max_features = 200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Select N best features and print them:\n",
    "from itertools import compress\n",
    "features = pd.DataFrame()\n",
    "features[\"idx\"] = sel.get_support(indices=True)\n",
    "features[\"importance\"] = sel.estimator.feature_importances_[features[\"idx\"]]\n",
    "features[\"names\"] =  np.array(vectorizer.get_feature_names_out())[features[\"idx\"]]\n",
    "features[\"prediction\"] = clf.predict(vectorizer.transform(features[\"names\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "########Feature extraction:\n",
    "#Create Feature selection tool:\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "sel = SelectFromModel(clf,prefit=True, max_features = 200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Select N best features and print them:\n",
    "from itertools import compress\n",
    "features = pd.DataFrame()\n",
    "features[\"idx\"] = sel.get_support(indices=True)\n",
    "features[\"importance\"] = sel.estimator.feature_importances_[features[\"idx\"]]\n",
    "features[\"names\"] =  np.array(vectorizer.get_feature_names_out())[features[\"idx\"]]\n",
    "features[\"prediction\"] = clf.predict(vectorizer.transform(features[\"names\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "########Feature extraction:\n",
    "#Create Feature selection tool:\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "sel = SelectFromModel(clf,prefit=True, max_features = 200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "#Select N best features and print them:\n",
    "from itertools import compress\n",
    "features = pd.DataFrame()\n",
    "features[\"idx\"] = sel.get_support(indices=True)\n",
    "features[\"importance\"] = sel.estimator.feature_importances_[features[\"idx\"]]\n",
    "features[\"names\"] =  np.array(vectorizer.get_feature_names_out())[features[\"idx\"]]\n",
    "features[\"prediction\"] = clf.predict(vectorizer.transform(features[\"names\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "       idx  importance           names  prediction\n0       12    0.001220       abl choos           1\n1      214    0.000815    accid situat           1\n2      223    0.000976   accident call           1\n3     1000    0.000741  announc corona           1\n4     1047    0.000541    announc time           1\n..     ...         ...             ...         ...\n195  22342    0.000562      would like           1\n196  22363    0.000619      would nice           1\n197  22379    0.000860   would possibl           1\n198  22455    0.000589    write number           1\n199  22486    0.001636     wrong place           1\n\n[200 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>idx</th>\n      <th>importance</th>\n      <th>names</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12</td>\n      <td>0.001220</td>\n      <td>abl choos</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>214</td>\n      <td>0.000815</td>\n      <td>accid situat</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>223</td>\n      <td>0.000976</td>\n      <td>accident call</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000</td>\n      <td>0.000741</td>\n      <td>announc corona</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1047</td>\n      <td>0.000541</td>\n      <td>announc time</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>22342</td>\n      <td>0.000562</td>\n      <td>would like</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>22363</td>\n      <td>0.000619</td>\n      <td>would nice</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>22379</td>\n      <td>0.000860</td>\n      <td>would possibl</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>22455</td>\n      <td>0.000589</td>\n      <td>write number</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>22486</td>\n      <td>0.001636</td>\n      <td>wrong place</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}